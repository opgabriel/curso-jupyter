{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T20:07:24.597099Z",
     "start_time": "2021-04-20T20:07:24.220697Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Importar os pacotes necess√°rios\n",
    "import pandas as pd\n",
    "#from fuzzywuzzy import fuzz\n",
    "#from itertools import combinations\n",
    "\n",
    "pd.set_option('display.max_columns', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepara√ß√£o de Dados para Ci√™ncia\n",
    "\n",
    "Em Ci√™ncia de Dados, dados de qualidade s√£o pr√©-requisito para pesquisas v√°lidas, descobertas significativas, modelos de Aprendizado de M√°quina, entre outros. Por√©m, no mundo real, dados brutos costumam ser incompletos, ruidosos, inconsistentes e, √†s vezes, est√£o em formato inutiliz√°vel. Portanto, antes de aliment√°-los a modelos (e outras etapas de pesquisa), √© fundamental averiguar a integridade de dados e identificar poss√≠veis problemas. Este processo √© denominado pr√©-processamento de dados.\n",
    "\n",
    "Essencialmente, preparar dados significa adequ√°-los para servirem de entrada nos processos da pesquisa. Existem muitas t√©cnicas de pr√©-processamento que, geralmente, acontecem em etapas organizadas nas seguintes categorias: Limpeza de Dados, Integra√ß√£o de Dados, Transforma√ß√£o de Dados, e Redu√ß√£o de Dados. As etapas do pr√©processamento n√£o s√£o mutuamente exclusivas e s√£o altamente dependentes do conjunto de dados; ou seja, podem trabalhar em conjunto, mas n√£o s√£o obrigat√≥rias.\n",
    "\n",
    "Em particular, a Limpeza de dados pode remover ru√≠do e corrigir inconsist√™ncias nos dados. A Integra√ß√£o de dados mescla dados de v√°rias fontes em um armazenamento de dados coerente, como um armaz√©m de dados. Transforma√ß√µes de dados, como normaliza√ß√£o, podem melhorar a precis√£o e efici√™ncia de algoritmos que envolvem medi√ß√µes de dist√¢ncia. Ent√£o, a Redu√ß√£o de dados pode diminuir o tamanho dos dados agregando ou eliminando recursos redundantes. Atrav√©s de exemplos com dados reais, esta se√ß√£o define e descreve cada uma dessas etapas t√©cnicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpeza de Dados\n",
    "\n",
    "A limpeza de dados √© o processo de **detec√ß√£o e corre√ß√£o de registros incorretos ou corrompidos** em um conjunto de dados. \n",
    "\n",
    "Ap√≥s a identifica√ß√£o de registros incorretos ou corrompidos, podemos:\n",
    "\n",
    "- substituir\n",
    "- modificar \n",
    "- excluir partes incompletas, imprecisas ou irrelevantes. \n",
    "\n",
    "> üí° Em geral, a limpeza de dados leva a uma **sequ√™ncia de tarefas** que visam melhorar a qualidade dos dados. Algumas dessas tarefas incluem n√£o s√≥ lidar com dados ausentes e duplicados, mas tamb√©m remover dados ruidosos, inconsistentes e outliers. \n",
    "\n",
    "Para come√ßar o processo de limpeza, primeiro vamos realizar a importa√ß√£o dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T20:07:25.366638Z",
     "start_time": "2021-04-20T20:07:25.331640Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ler a tabela modificada\n",
    "df = pd.read_csv('../dataset/spotify_artists_info_edited.csv', sep='\\t', encoding='utf-8')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados ausentes \n",
    "\n",
    "Representam um obst√°culo para a cria√ß√£o da maioria dos modelos de Aprendizado de M√°quina e outras an√°lises. Portanto, √© necess√°rio identificar **campos para os quais n√£o h√° dados** e, em seguida, compens√°-los adequadamente. \n",
    "\n",
    "Dados ausentes podem ocorrer quando nenhuma informa√ß√£o √© fornecida para um ou mais registros (ou atributos inteiros) da base de dados. Em um _**Pandas DataFrame**_, os dados ausentes s√£o representados como **`None`** ou **`NaN`** (_Not a Number_).\n",
    "\n",
    "> ‚ö†Ô∏è **`NaN`** √© o marcador de valor ausente **padr√£o** por raz√µes de velocidade e conveni√™ncia computacional. \n",
    "\n",
    "Ap√≥s importar pacotes necess√°rios e carregar o conjunto de dados, inicia-se o processo de limpeza de dados. Para facilitar a detec√ß√£o, o __Pandas__ fornece a fun√ß√£o **`isna()`** para identificar valores ausentes em um _DataFrame_.\n",
    "\n",
    "A fun√ß√£o retorna uma **matriz booleana** indicando se cada elemento correspondente est√° faltando **(`True`) ou n√£o (`False`)**. O exemplo a seguir apresenta o uso desta fun√ß√£o no *DataFrame* `df` e exibe seu resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta c√©lula identifica valores ausentes no Dataframe\n",
    "df.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acordo com o resultado da c√©lula anterior, o conjunto de dados est√° **aparentemente** completo. \n",
    "\n",
    "> ‚ö†Ô∏è Por√©m, isso n√£o √© suficiente para descartar a hip√≥tese de que **existem dados ausentes.**\n",
    "\n",
    "Para uma melhor averigua√ß√£o, pode-se resumir cada coluna no _DataFrame booleano_ somando os valores **False = 0**  e **True = 1** . Tal processo retorna o n√∫mero de valores ausentes no _DataFrame_. \n",
    "\n",
    "Tamb√©m pode-se dividir cada valor pelo n√∫mero total de linhas, resultando na **porcentagem de tais aus√™ncias**, conforme o exemplo a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T20:09:52.004424Z",
     "start_time": "2021-04-20T20:09:51.979435Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# Calcular o total e a porcentagem de valores ausentes\n",
    "\n",
    "## retorna o total de valores ausentes de cada coluna\n",
    "num_ausentes = df.isna().sum() \n",
    "\n",
    "## retorna a porcentagem de valores ausentes de cada coluna\n",
    "porc_ausentes = df.isna().sum() * 100 / len(df)\n",
    "\n",
    "# Cria um DataFrame com as informa√ß√µes computadas acima\n",
    "df_ausentes = pd.DataFrame({\n",
    "    'Coluna': df.columns,\n",
    "    'Dados ausentes': num_ausentes,\n",
    "    'Porcentagem': porc_ausentes\n",
    "})\n",
    "df_ausentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O _DataFrame_ resultante cont√©m os seguintes dados **ausentes**:\n",
    "- **62** popularidades\n",
    "- **40** listas de g√™neros e \n",
    "- **10** url de imagens\n",
    "\n",
    "O que resulta em 9,9%, 6,4% e 1,6% as porcentagens de registros ausentes de cada coluna, respectivamente. \n",
    "\n",
    "Ap√≥s essa identifica√ß√£o, √© necess√°rio **tratar esses dados**. \n",
    "\n",
    "> üí° A abordagem mais simples √© **eliminar todos os registros que contenham valores ausentes**. \n",
    "No _Pandas_, o m√©todo **dropna()** permite analisar e descartar linhas/colunas com valores nulos. \n",
    "\n",
    "O par√¢metro **axis** determina a dimens√£o em que a fun√ß√£o atuar√°: \n",
    "- **axis = 0** remove todas as _linhas_ que cont√™m valores nulos\n",
    "- **axis = 1** remove as _colunas_ que cont√™m valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminando as linhas onde pelo menos um elemento est√° faltando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "novo_df = df.dropna(axis=0) # retorna para um novo dataframe, sem as linhas que cont√©m nulos\n",
    "\n",
    "print(f\"\"\"\\\n",
    "N¬∫ de linhas do DF original: {len(df)}\n",
    "N¬∫ de linhas do DF novo: {len(novo_df)}\n",
    "N¬∫ de linhas com pelo menos 1 valor ausente: {\n",
    "(len(df) - len(novo_df))}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminando as colunas onde pelo menos um elemento est√° faltando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "novo_df = df.dropna(axis=1) # retorna para um novo dataframe, sem as colunas que cont√©m nulos\n",
    "\n",
    "print(f\"\"\"\\\n",
    "N¬∫ de colunas do DF original: {len(df.columns)}\n",
    "N¬∫ de colunas do DF novo: {len(novo_df.columns)}\n",
    "N¬∫ de colunas com pelo menos 1 valor ausente: {\n",
    "(len(df.columns) - len(novo_df.columns))}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è ATEN√á√ÉO!‚ö†Ô∏è\n",
    "\n",
    "O c√≥digo dos exemplos anteriores **removeram as linhas/colunas onde pelo menos um elemento est√° faltando**. \n",
    "\n",
    "Ambas abordagens s√£o particularmente vantajosas para amostras de **grande volume de dados**, onde os valores podem ser descartados sem distorcer significativamente a interpreta√ß√£o. Em geral, a estrat√©gia de exclus√£o √© utilizada quando o problema de falta de dados ocorre na **maioria** das linhas ou colunas do conjunto de dados. Por exemplo, se mais de 75% das linhas correspondentes a um atributo (coluna) s√£o ausentes, √© melhor remover tal atributo.\n",
    "\n",
    "> üí°  Vale lembrar que esse valor de 75% de dados ausentes **n√£o √© uma regra**, e n√£o h√° uma receita de bolo: tudo vai depender dos seus dados e dos seus objetivos.\n",
    "\n",
    "> ‚ö†Ô∏è No entanto, apesar de ser uma solu√ß√£o simples, ela **apresenta o risco de perder dados potencialmente √∫teis**.\n",
    "\n",
    "### Solu√ß√£o Alternativa - Imputar Dados üé≤üé≤\n",
    "\n",
    "Uma alternativa mais confi√°vel para lidar com dados ausentes √© a **imputa√ß√£o**. Em vez de descartar tais dados, a imputa√ß√£o procura **substituir seus valores por outros**. Nessa abordagem, os valores ausentes s√£o inferidos a partir dos dados existentes. \n",
    "\n",
    "> üí° Existem v√°rias maneiras de imputar os dados, sendo a imputa√ß√£o por valor constante ou por estat√≠sticas b√°sicas **(m√©dia, mediana ou moda)** as mais simples.\n",
    "\n",
    "No exemplos a seguir, os valores de colunas ausentes ser√£o substitu√≠dos utilizando a fun√ß√£o `fillna()`. Mas antes, vamos criar uma c√≥pia do _DataFrame_ original para trabalharmos com ele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma c√≥pia do DataFrame original\n",
    "copia_df = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputando dados na coluna _`image_url`_\n",
    "\n",
    "Substituindo todos os dados ausentes da coluna **'image_url'** por um valor est√°tico \n",
    "\n",
    "Por exemplo, podemos inserir a url de imagem _default_ em todas as linhas em que este campo encontra-se nulo.\n",
    "\n",
    "![Imagem](./img/default-user-icon-1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copia_df[\"image_url\"].fillna('https://icon-library.com/icon/default-user-icon-1.html', inplace=True)\n",
    "copia_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputando dados na coluna _`popularity`_\n",
    "\n",
    "Neste caso, como esta √© uma coluna num√©rica, podemos substituir todos os dados ausentes da coluna _popularity_ pela **m√©dia dos valores presentes na coluna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitui NaNs pela m√©dia de valores presentes\n",
    "copia_df['popularity'].fillna(copia_df['popularity'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üí° OBS: Quando **inplace='True'** √© passado, os dados s√£o alterados no pr√≥prio dataframe (n√£o retorna nada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# Coluna Popularity do Dataframe Original\n",
    "df['popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# Coluna Popularity do Dataframe ap√≥s a Imputa√ß√£o da m√©dia da popularidade em campos NaN\n",
    "copia_df['popularity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputando dados na coluna _`genres`_\n",
    "\n",
    "Neste caso, como n√£o seria vi√°vel analisar cada artista separadamente para tentar inferir seu g√™nero musical, uma op√ß√£o √© substituir os valores ausentes por _**unknown**_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituir NaNs por 'unknown'\n",
    "copia_df['genres'].fillna('unknown', inplace=True)\n",
    "\n",
    "# Coluna Genres ap√≥s imputa√ß√£o\n",
    "copia_df['genres'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üí° Para saber quais os √≠ndices que cont√©m o valor 'unknown':\n",
    "<br>\n",
    "``\n",
    "np.where(copia_df['genres']=='unknown')\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando se todos os valores 'NaN' foram devidamente preenchidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula o total e a % de valores ausentes\n",
    "num_ausentes = copia_df.isna().sum() \n",
    "porc_ausentes = copia_df.isna().sum() * 100 / len(copia_df)\n",
    "\n",
    "# DataFrame com as informa√ß√µes computadas acima\n",
    "df_ausentes = pd.DataFrame({\n",
    "    'Coluna': copia_df.columns,\n",
    "    'Dados ausentes': num_ausentes,\n",
    "    'Porcentagem': porc_ausentes\n",
    "})\n",
    "df_ausentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tamb√©m existem v√°rias t√©cnicas de imputa√ß√£o avan√ßadas cuja escolha depende da utiliza√ß√£o dos dados, por exemplo, depende de **um modelo de aprendizado de m√°quina** para inserir e avaliar com precis√£o os dados ausentes. A imputa√ß√£o m√∫ltipla e modelos preditivos podem ser mais precisos, e assim s√£o mais comuns do que m√©todos mais simples. \n",
    "\n",
    "> üí° **n√£o existe uma maneira ideal de compensar os valores ausentes**, pois cada estrat√©gia pode ter um desempenho melhor ou pior dependendo do conjunto de dado e dos tipos de dados ausentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados ruidosos üé≤üì¢\n",
    "\n",
    "S√£o dados que fornecem informa√ß√µes adicionais por√©m **sem sentido**, chamadas de ru√≠do. Geralmente s√£o gerados por alguma falha na coleta de dados, erros de entrada de dados, entre outros. Dados com ru√≠do podem prejudicar resultados de an√°lises e de modelos, como os de aprendizado de m√°quina, por exemplo. \n",
    "\n",
    "> üí° Algumas solu√ß√µes para tal problema incluem diferentes abordagens: tais como o m√©todo de **Binning**, **Regress√£o** e e algoritmos de agrupamento de dados (**Clustering**). \n",
    "\n",
    "Aqui, o foco √© o m√©todo de **Binning**, uma t√©cnica de **suaviza√ß√£o de dados** para reduzir os efeitos de pequenos erros de observa√ß√£o. \n",
    "\n",
    "Os dados originais s√£o divididos em segmentos de tamanhos iguais (_**bins**_) e, em seguida, s√£o substitu√≠dos por um valor geral calculado para cada intervalo. Cada segmento √© tratado separadamente, onde a substitui√ß√£o de valores pode ser realizada atrav√©s de valores m√©dios ou limites. \n",
    "\n",
    "> ‚ö†Ô∏è No _Pandas_, o m√©todo Binning usa as fun√ß√µes `cut()` e `qcut()`, que parecem iguais mas possuem diferen√ßas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `qcut`\n",
    "\n",
    "De acordo com a documenta√ß√£o, `qcut()` √© uma **fun√ß√£o de discretiza√ß√£o baseada em quantis**: ela procura dividir os dados em _bins_ usando percentis com base na distribui√ß√£o da amostra. \n",
    "\n",
    "A maneira mais simples de us√°-la √© **definir o n√∫mero de quantis** e deixar que o _Pandas_ descubra como dividir os dados. \n",
    "\n",
    "O exemplo a seguir discretiza a vari√°vel **_followers_** de duas maneiras diferentes: \n",
    "- criando cinco _bins_ de mesmo tamanho\n",
    "- configurando tr√™s quantis rotulados como \"alto\", \"m√©dio\" e \"baixo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretiza a vari√°vel 'followers' em 5 intervalos de tamanhos iguais\n",
    "df['qcut_1'] = pd.qcut(df['followers'], q=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretiza a vari√°vel 'followers' setamos tr√™s quantis rotulados como 'alto', 'm√©dio' e 'baixo'\n",
    "df['qcut_2'] = pd.qcut(df['followers'],  q=[0, .3, .7, 1], labels=[\"baixo\", \"m√©dio\", \"alto\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir o resultado das divis√µes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `cut`\n",
    "\n",
    "Pode-se utilizar a fun√ß√£o `cut()` para segmentar e ordenar os dados em _bins_. Enquanto `qcut()` calcula o tamanho de cada _bin_, garantindo que a distribui√ß√£o dos dados nos compartimentos seja igual, a fun√ß√£o `cut()` **define bordas exatas dos compartimentos**. \n",
    "\n",
    "> ‚ö†Ô∏è Neste caso n√£o h√° garantia sobre a distribui√ß√£o de itens em cada _bin_. \n",
    "\n",
    "O exemplo a seguir corta os dados da vari√°vel _**followers**_ em quatro bins de tamanhos iguais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretiza a vari√°vel 'followers' em 4 bins\n",
    "df['cut_1'] = pd.cut(df['followers'], bins=4)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme mostrado a seguir, se voc√™ deseja uma distribui√ß√£o igual dos valores em cada compartimento, use `qcut()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df['qcut_1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso contr√°rio, se voc√™ quiser definir seus pr√≥prios intervalos num√©ricos de categorias, use a fun√ß√£o `cut()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "df['cut_1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "\n",
    "S√£o amostras de dados que s√£o **claramente diferentes da tend√™ncia central**. Geralmente s√£o criados por erros de coleta ou entrada de dados, e podem facilmente **produzir valores discrepantes** interferindo na qualidade de an√°lises. \n",
    "\n",
    "> üí° A maneira mais simples de identificar outliers √© **observar os valores m√°ximos e m√≠nimos** em cada vari√°vel para ver se eles est√£o muito fora da curva normal. \n",
    "\n",
    "\n",
    "O exemplo a seguir utiliza a fun√ß√£o `describe()` para gerar estat√≠sticas descritivas do conjunto de dados, incluindo os valores m√°ximos e m√≠nimos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "# Gera estat√≠sticas descritivas das vari√°veis num√©ricas\n",
    "df.describe().round().transpose() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üí° Para arredondar valores, use a fun√ß√£o `.round()`\n",
    "<br>\n",
    "Para exibir a matriz transposta: `.transpose()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a coluna _followers_, o valor m√°ximo √© 77.7 milh√µes de seguidores, enquanto o quartil de 75% √© apenas 48 milh√µes. Portanto, artistas com mais de 77 milh√µes de seguidores **podem ser outliers**. \n",
    "\n",
    "Essa verifica√ß√£o geral √© melhor realizada atrav√©s da representa√ß√£o gr√°fica dos dados num√©ricos por meio de seus quartis. Para isso, pode-se utilizar **box plots**, onde os valores discrepantes s√£o plotados como pontos individuais. \n",
    "\n",
    "> üí° Este tipo de visualiza√ß√£o ser√° melhor abordado mais adiante!\n",
    "\n",
    "O gr√°fico do exemplo a seguir mostra a distribui√ß√£o da vari√°vel **_followers_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# Plota um boxplot da coluna 'followers'\n",
    "df.boxplot(column=['followers'], figsize=(15, 3), vert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O exemplo ilustra que existem in√∫meros pontos individuais (outliers) entre aproximadamente **12** a **78 milh√µes** (observe que o eixo x est√° em dezenas de milh√µes). \n",
    "\n",
    "Embora tenha sido f√°cil detectar tais valores discrepantes, √© preciso determinar as solu√ß√µes adequadas para trat√°-los. Assim como no caso de dados ausentes, o tratamento de outliers **depende muito do conjunto de dados e do objetivo do projeto**. Solu√ß√µes poss√≠veis incluem:\n",
    "\n",
    "- manter\n",
    "- ajustar \n",
    "- ou apenas remover os dados discrepantes\n",
    "\n",
    "Uma t√©cnica comum para a remo√ß√£o de outliers √© o m√©todo de **Z-score**, que considera como outliers e remove valores a uma determinada quantidade de desvios padr√µes da m√©dia. A quantidade desses desvios pode variar conforme o tamanho da amostra.\n",
    "\n",
    "No exemplo a seguir, para identificar e remover os outliers da coluna **_followers_**, usou-se os z-scores de seus registros com a quantidade de desvios configurada para tr√™s. Para a obten√ß√£o dos z-scores, foi usado o m√≥dulo `stats` da biblioteca `SciPy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa os pacotes necess√°rios\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Calcula os z-scores dos valores da coluna 'followers'\n",
    "z_scores = stats.zscore(df['followers'])\n",
    "\n",
    "# Converte cada elemento em z_scores em seu valor absoluto\n",
    "# fun√ß√£o `abs` de Numpy\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "\n",
    "# Filtra o DataFrame original com uma quantidade de desvios padr√µes < 3\n",
    "novo_df = df[abs_z_scores < 3]\n",
    "\n",
    "print(f'{(len(df) - len(novo_df))} foram outliers removidos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados duplicados\n",
    "\n",
    "Aparecem em muitos contextos, especialmente durante a entrada ou coleta de dados. Por exemplo, ao usar um _web scraper_, a mesma p√°gina web pode ser coletada mais de uma vez, ou as mesmas informa√ß√µes podem estar em p√°ginas diferentes. \n",
    "\n",
    "> ‚ö†Ô∏è Independente da causa, a duplica√ß√£o de dados **pode levar a conclus√µes incorretas**, onde algumas observa√ß√µes podem ser consideradas mais comuns do que realmente s√£o. \n",
    "\n",
    "O exemplo a seguir mostra quantas linhas est√£o duplicadas em cada coluna do conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# Calcula o total de linhas duplicadas em cada coluna do nosso DataFrame\n",
    "# Para cada coluna,\n",
    "for coluna in df.columns:\n",
    "    # Seleciona linhas duplicadas e as insire em um novo Dataframe\n",
    "    duplicatas_df = df[df.duplicated(coluna)]\n",
    "    \n",
    "    # Imprime o tamanho do novo DataFrame (i.e., o n√∫mero de linhas duplicadas)\n",
    "    print(f\"Total de linhas duplicadas \"\n",
    "          f\"na {coluna}: {len(duplicatas_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que apenas duas colunas do _DataFrame_ n√£o possuem duplicatas: **artist_id** e **followers**. \n",
    "\n",
    "Al√©m disso, observem que h√° **duas c√≥pias do nome de um mesmo artista**. Essa duplicidade de dados √© a categoria mais simples de duplicatas: s√£o c√≥pias exatamente iguais de um mesmo registro. Para resolver, basta identificar os valores id√™nticos e remov√™-los. \n",
    "\n",
    "O _Pandas_ fornece o m√©todo **`drop_duplicates()`** que retorna um novo _DataFrame_ com linhas duplicadas removidas, como no exemplo a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna um novo DataFrame com linhas duplicadas removidas\n",
    "novo_df = df.drop_duplicates()\n",
    "\n",
    "# Calcula o total de linhas duplicadas do novo DataFrame\n",
    "duplicatas_df = novo_df[novo_df.duplicated()]\n",
    "print(f\"Total de linhas duplicadas: {len(duplicatas_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com apenas uma lista de registros com duplicatas, a melhor e mais simples solu√ß√£o √© geralmente a remo√ß√£o. Por√©m, com dados tabulares, a melhor solu√ß√£o √© remover os dados duplicados com base em um **conjunto de identificadores exclusivos**. \n",
    "\n",
    "Por exemplo, existe a coluna de identificadores √∫nicos dos artistas (**_`artist_id`_**), que facilita analisar se o nome duplicado identificado pode ser descartado, conforme o seguinte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 5)\n",
    "# Extrai o nome duplicado\n",
    "nome_duplicado = df[df.duplicated(['name'])].name\n",
    "\n",
    "# Localiza as linhas onde 'name' √© igual ao nome duplicado\n",
    "df.loc[df['name'].isin(nome_duplicado)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados mostram dois artistas com o nome **Niack**, mas com identificadores √∫nicos `diferentes`. \n",
    "\n",
    "> ‚ö†Ô∏è Neste caso, n√£o se pode descartar uma das supostas c√≥pias. \n",
    "\n",
    "Existem ainda outras formas de duplica√ß√£o de dados mais complexas, onde mais de um registro √© associado √† mesma observa√ß√£o, por√©m seus valores n√£o s√£o completamente id√™nticos. Por exemplo, nomes pr√≥prios com e sem abrevia√ß√£o ou omiss√£o de algum dos sobrenomes. Essa duplica√ß√£o parcial √© **bem mais dif√≠cil de identificar**, pois requer entender se realmente os registros duplicados dizem respeito ao mesmo objeto. \n",
    "\n",
    "Nesses casos, uma solu√ß√£o comum √© utilizar **fun√ß√µes de similaridade de strings.** \n",
    "\n",
    "Uma ferramenta poderosa para esse problema √© a biblioteca Python _`FuzzyWuzzy`_, que usa a dist√¢ncia de Levenshtein para calcular as diferen√ßas entre duas strings. \n",
    "\n",
    "No exemplo a seguir, n√≥s utilizamos duas fun√ß√µes, `ratio()` e `partial_ratio()`, para encontrar c√≥pias n√£o id√™nticas de nomes de artistas. O c√≥digo retorna dois prov√°veis casos de duplica√ß√£o parcial.\n",
    "\n",
    "**No primeiro**, ao pesquisarmos a fundo, descobrimos que os dois nomes identificam duas artistas distintas. Portanto, n√£o podemos remover essas supostas c√≥pias. \n",
    "\n",
    "No entanto, **no segundo caso**, \"Red Velvet\" denomina o mesmo grupo feminino sul-coreano, por√©m o nome \"Red Velvet - Irene & Seulgi\" foi cadastrado na plataforma Spotify para representar a primeira subunidade do grupo (composto por Irene e Seulgi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa os pacotes necess√°rios\n",
    "from fuzzywuzzy import fuzz\n",
    "from itertools import combinations\n",
    "\n",
    "# Gera todas as combina√ß√µes poss√≠veis de dois elementos (nomes) da coluna 'name'\n",
    "combinacoes = combinations(df.name, 2)\n",
    "\n",
    "# Para cada tupla de nomes presente na lista de combina√ß√µes,\n",
    "for nome_1, nome_2 in list(combinacoes):\n",
    "    \n",
    "    # Calcula a similaridade parcial dos dois nomes\n",
    "    partial_ratio = fuzz.partial_ratio(nome_1, nome_2)\n",
    "    \n",
    "    # Calcula a similaridade simples dos dois nomes\n",
    "    ratio = fuzz.ratio(nome_1, nome_2)\n",
    "    \n",
    "    # Se os nomes forem parcialmente iguais, por√©m n√£o identicos,\n",
    "    if partial_ratio == 100 and ratio < 100 and ratio > 50:\n",
    "        \n",
    "        # Imprime os dois nomes e a pontua√ß√£o das similaridades computadas\n",
    "        print(nome_1, ' | ', nome_2)\n",
    "        print(partial_ratio, ' | ', ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è  ERRO de Biblioteca ‚ö†Ô∏è \n",
    "\n",
    "Se o seguinte erro ocorrer, √© devido √† falta da biblioteca utilizada em seu ambiente python.\n",
    "\n",
    "![Erro de Lib](./img/Erro_fuzzy.png)\n",
    "\n",
    "Para resolver, podemos utilizar o comando de importa√ß√£o como no exemplo seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala a biblioteca\n",
    "!pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desinstala a biblioteca\n",
    "!pip uninstall fuzzywuzzy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclus√£o\n",
    "\n",
    "Este notebook apresentou como fazer a limpeza inicial de dados de dados.\n",
    "\n",
    "> üîé Se interessou? D√™ uma olhada na documenta√ß√£o da biblioteca pandas para informa√ß√µes extras sobre fun√ß√µes de manipula√ß√£o de dados: [User Guide](https://pandas.pydata.org/docs/user_guide/index.html)\n",
    "---\n",
    "\n",
    "A pr√≥xima parte ([4.Transformacao](../4.Transformacao/4.1.Integracao.ipynb)) apresenta como fazer a integra√ß√£o, transforma√ß√£o e redu√ß√£o de dados de v√°rias fontes."
   ]
  }
 ],
 "metadata": {
  "julynter-results": {
   "filteredId": [],
   "filteredIndividual": [],
   "filteredRestart": [],
   "filteredType": [],
   "hash": "3e97903641083aa633eee000628a202ffd7c34e3",
   "visible": [
    {
     "cellId": "group",
     "hash": "c0de46ba034d710c2b2406a37ee6816be9634aa0",
     "reason": "This groups other lint messages",
     "reportId": "group",
     "reportType": "hiddenstate",
     "suggestion": null,
     "text": "Hidden State"
    },
    {
     "cellId": 2,
     "hash": "71d2b721a8a21948e50ef4dcebaa8038e9e7b930",
     "reason": "A skip in the execution count might indicate the presence of a hidden state caused by a cell that does not exist anymore. Hidden states might prevent cells from executing or producing the same results, hampering the reproducibility.",
     "reportId": "h4",
     "reportType": "hiddenstate",
     "suggestion": "Please consider re-running the notebook to guarantee the reproducibility.",
     "text": "Cell 2 skips the execution count"
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

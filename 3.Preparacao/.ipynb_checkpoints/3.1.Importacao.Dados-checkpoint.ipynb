{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importar Bibliotecas \n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que jÃ¡ conhecemos um pouco sobre as principais estruturas do Pandas (*Series e Dataframes*), agora Ã© a vez de aprender a como **importar dados** para tais estruturas.\n",
    "\n",
    "> Embora a criaÃ§Ã£o de estruturas de dados de forma manual seja Ãºtil para determinadas aplicaÃ§Ãµes ou atÃ© mesmo para rÃ¡pidos testes e validaÃ§Ãµes, na prÃ¡tica, a nossa fonte de ðŸŽ²ðŸŽ² normalmente serÃ¡ via enormes arquivos!\n",
    "\n",
    "Em ciÃªncia de dados, muitos projetos obrigam seus cientistas a reunir uma miscelÃ¢nea de padrÃµes de fontes de dados, tais como **CSV**, **TSV**, **XLS**, **JSON**, ou outro formato. Assim, Ã© crucial saber lidar com os principais formatos de dados em Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquivos Texto - CSV\n",
    "\n",
    "Um dos formatos **mais utilizados** Ã© o CSV, que nada mais sÃ£o que arquivos de texto **separados por vÃ­rgulas**. A figura abaixo mostra um arquivo CSV.\n",
    "\n",
    "![Exemplo de Arquivo CSV](./img/CSV.png)\n",
    "\n",
    "> **Como importar importar arquivos CSV utilizando o pandas?** ðŸ¤”\n",
    "\n",
    "Simples! Basta segui os comandos abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spotify_Charts_df = pd.read_csv('./datasets/spotify_charts_complete.csv', sep=',')\n",
    "spotify_Charts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "â €â €â €â €â €â €â €â €â €\n",
    "â €â €â €â €â €â €â €â €â €\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "â €â €â €â €â €â €â €â €â €\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "â €â €â €â €â €â €â €â €â €\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "â €â €â €â €â €â €â €â €â €\n",
    "â €â €â €â €â €â €â €â €â €\n",
    "â €â €â €â €â €â €â €â €â €\n",
    "â €â €â €â €â €â €â €â €â €\n",
    "â €â €â €â €â €â €â €â €â €\n",
    "â €â €â €â €â €â €â €â €â €\n",
    "â €â €â €â €â €â €â €â €â €\n",
    "\n",
    "â €â €â €â €â €â €â €â €â €\n",
    "\n",
    "â €â €â €â €â €â €â €â €â €\n",
    "\n",
    "â €â €â €â €â €â €â €â €â €\n",
    "\n",
    "â €â €â €â €â €â €â €â €â €\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erro na Linha 46: âŒ\n",
    "\n",
    "\n",
    "Note que nÃ³s temos **seis** colunas do arquivo de entrada: \n",
    "- chart_week\n",
    "- position\n",
    "- track_name\n",
    "- artist\n",
    "- streams\n",
    "- song_id\n",
    "\n",
    "> **Como o Pandas estÃ¡ enxergando a linha: 46** ðŸ”Ž\n",
    "\n",
    " _2020-01-02$\\color{#ff0000}{,}$45$\\color{#ff0000}{,}$10$\\color{#ff0000}{,}$**000 Hours (with Justin Bieber)**$\\color{#ff0000}{,}$Dan + Shay$\\color{#ff0000}{,}$10360035$\\color{#ff0000}{,}$2wrJq5XKLnmhRXHIAf9xBa_\n",
    "\n",
    "> **Como o Pandas deveria enxergar:** ðŸ‘€\n",
    "\n",
    " _2020-01-02$\\color{#ff0000}{,}$45$\\color{#ff0000}{,}$**10,000 Hours (with Justin Bieber)**$\\color{#ff0000}{,}$Dan + Shay$\\color{#ff0000}{,}$10360035$\\color{#ff0000}{,}$2wrJq5XKLnmhRXHIAf9xBa_\n",
    " \n",
    "Erro de **tokenizaÃ§Ã£o** Ã© um problema muito comum quando lidamos com arquivos CSV. \n",
    "\n",
    "> **Como resolver esse problema?** ðŸ¤”\n",
    "\n",
    "Neste caso, para que esse tipo de erro seja evitado, terÃ­amos que **escapar todas as Strings usando aspas (')**. Desta forma, todas as vÃ­rgulas de campos textuais nÃ£o serÃ£o consideradas como separador de campo. Ou seja, todas as linhas do arquivo deveriam se parecer com:\n",
    "\n",
    "_'2020-01-02',45,**'10,000 Hours (with Justin Bieber)'**,**'Dan + Shay'**,10360035,2wrJq5XKLnmhRXHIAf9xBa_\n",
    "\n",
    "> Embora nÃ£o seja necessÃ¡rio, Ã© comum que todos os campos de arquivos CSVs sejam escapados por aspas, nÃ£o se limitando apenas aos campos textuais! ðŸ¤“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leitura sem erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_Charts_df = pd.read_csv('./datasets/spotify_charts_complete_Line45.csv', sep=',')\n",
    "spotify_Charts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquivos Texto - TSV\n",
    "\n",
    "Uma alternativa aos arquivos CSV, sÃ£o os arquivos TSV (valores separados por tabulaÃ§Ã£o). Neste tipo de arquivo, como o delimitador de campo Ã© uma **tabulaÃ§Ã£o**, nÃ£o deparamos com o problema de tokenizaÃ§Ã£o. \n",
    "\n",
    "A figura abaixo mostra um arquivo TSV.\n",
    "\n",
    "![Exemplo de Arquivo TSV](./img/TSV.png)\n",
    "\n",
    " A leitura deste tipo de arquivo Ã© feita utilizando a mesma funÃ§Ã£o **read_csv**. No entanto, precisamos especificar que o separador Ã© a tabulaÃ§Ã£o (\\t). \n",
    " \n",
    " > âš ï¸ Se nÃ£o for especificado o delimitador, o python retornarÃ¡ um erro de **Parser**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_Charts_df = pd.read_csv('./datasets/spotify_charts_complete.tsv', sep='\\t')\n",
    "spotify_Charts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ðŸ’¡ Uma funÃ§Ã£o alternativa para a leitura de arquivos deste tipo Ã© a **read_table()**\n",
    "\n",
    "Neste caso, nÃ£o Ã© necessÃ¡rio o uso de outros parÃ¢metros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A funÃ§Ã£o read_table Ã© utilizada para ler arquivos .tsv\n",
    "charts = pd.read_table('./datasets/spotify_charts_complete.tsv')\n",
    "charts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquivos de Planilhas - XLS\n",
    "\n",
    "Outro formato bastante popular sÃ£o os arquivos que jÃ¡ se encontram em estrutura tabulares, tais como arquivos do Microsoft Excel. A figura abaixo mostra um arquivo XLS.\n",
    "\n",
    "![Exemplo de Arquivo XLS](./img/XLSX.png)\n",
    "\n",
    "O pandas possui a funÃ§Ã£o **read_excel(â€˜arquivo.xlsxâ€™)** para efetuar a leitura de arquivos em formato de planilhas eletrÃ´nicas.\n",
    "\n",
    "> âš ï¸ Para a importaÃ§Ã£o de uma **planilha especÃ­fica** em um mesmo arquivo (uma **aba**), Ã© preciso utilizar o parÃ¢metro **sheet_name**.\n",
    "\n",
    "Na figura acima, o arquivo chamado â€˜dados.xlsxâ€™ possui duas abas: _**spotify_artists**_ e _**spotify_charts**_. \n",
    "\n",
    "Para importar apenas o conteÃºdo da segunda aba (**spotify_charts**) do arquivo dados.xlsx, programa-se: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_charts = pd.read_excel ('./datasets/dados.xlsx', sheet_name='spotify_charts')\n",
    "spotify_charts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### âš ï¸ Caso o `sheet_name` nÃ£o seja especificado, importa-se a primeira aba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_artists = pd.read_excel ('./datasets/dados.xlsx')\n",
    "spotify_artists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquivos JSON (JavaScript Object Notation)\n",
    "\n",
    "Um arquivo JSON armazena estruturas de dados simples, alÃ©m de serem leves, textuais, legÃ­veis por humanos e editÃ¡veis com editor de texto. Arquivos JSON representam dados com o conceito de chave e valor:\n",
    "\n",
    "cada valor tem uma chave que descreve seu significado. Por exemplo, o par de _**chave:valor**_ **name:â€˜Michael Jacksonâ€™** representa o artista â€˜Michael Jacksonâ€™. A figura abaixo mostra um trecho de um arquivo JSON.\n",
    "\n",
    "![Exemplo de Arquivo JSON](./img/JSON.png)\n",
    "\n",
    "> ðŸ’¡  Note que Ã© possÃ­vel compreender os dados, e alterÃ¡-los utilizando um editor de texto.\n",
    "\n",
    "\n",
    "Para importar arquivos JSON, o pandas tem a funÃ§Ã£o **read_json()**, com funcionamento similar Ã s anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tracks = pd.read_json('./datasets/Michael_Jackson_tracks.json')\n",
    "tracks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entanto, a saÃ­da acima parece um pouco desajeitada, certo? ðŸ¤”\n",
    "\n",
    "Isso acontece pois este Ã© um arquivo **JSON aninhado**, ou seja, ele possui vÃ¡rios nÃ­veis de pares [chave:valor]. \n",
    "\n",
    "O primeiro nÃ­vel Ã© a chave _**tracks**_, ou seja, cada linha do dataframe retornado Ã© um valor para 'track'. Neste caso, nÃ£o Ã© possÃ­vel transformar um arquivo JSON __aninhado__ diretamente em um dataframe, pois a funÃ§Ã£o __*read_json*__ faz a leitura de strings JSON mais simples.\n",
    "\n",
    "Para o nosso exemplo, a obtenÃ§Ã£o de um dataframe organizado demanda a divisÃ£o deste JSON aninhado. Para isso, a funÃ§Ã£o *__json_normalize()__* Ã© utilizada para ler a __STRING__ JSON aninhada e devolver um DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Precisamos importar a biblioteca JSON\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primeiro Passo:\n",
    "ler a string JSON com a funÃ§Ã£o **json.loads()** da biblioteca JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets/Michael_Jackson_tracks.json','r') as f:\n",
    "    data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segundo Passo: \n",
    "\n",
    "Passamos o objeto JSON (data) para a funÃ§Ã£o **json_normalize()** que retornarÃ¡ um DataFrame contendo os dados necessÃ¡rios. Para isso, Ã© preciso informar o primeiro nÃ­vel de chave (_tracks_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df = pd.json_normalize(data['tracks'])\n",
    "\n",
    "tracks_df.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coluna __*artists*__ tambÃ©m Ã© composta por mais um nÃ­vel do arquivo json. \n",
    "\n",
    "Para melhor visualizar esta coluna, Ã© preciso repetir o processo acima construindo um novo dataframe, no entanto Ã© preciso informar a linha que se deseja recuperar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_df = pd.json_normalize(data['tracks'][0]['artists'])\n",
    "\n",
    "artist_df.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outros formatos\n",
    "\n",
    "AlÃ©m desses formatos, Ã© possÃ­vel carregar dados de XML e de bancos de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'TJSE')\n",
      "(2, 'TRIBUNAL DE JUSTICA DO ESTADO DE GOIAS')\n",
      "(3, 'TJPR')\n",
      "(4, 'TRIBUNAL DE JUSTIÃ‡A DO ESTADO DE MATO GROSSO')\n",
      "(5, 'TJ-TO')\n",
      "(6, 'JFTO')\n",
      "(7, 'JFMG')\n",
      "(8, 'Poder JudiciÃ¡rio do RN')\n",
      "(9, 'TRIBUNAL DE JUSTIÃ‡A DO ESTADO DO PIAUÃ')\n",
      "(10, 'TRIBUNAL DE JUSTICA DO ESTADO DO CEARA')\n"
     ]
    }
   ],
   "source": [
    "# Primeiro, importa o driver para o MySQL\n",
    "import mysql.connector\n",
    "\n",
    "# O seguinte cÃ³digo faz a conexÃ£o:\n",
    "conn = mysql.connector.connect(user='jai',              # Seu User\n",
    "                                password='senha',       # Sua senha\n",
    "                                host='127.0.0.1',       # EndereÃ§o do servidor\n",
    "                                database='jusbd')       # Base de Dados\n",
    "\n",
    "# Criar um cursor\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Elabora uma consulta\n",
    "query = (\"SELECT * from orgÃ£o limit 10\")\n",
    "\n",
    "# Executa a consulta\n",
    "cursor.execute(query)\n",
    "\n",
    "# Exibe o resultado da consulta\n",
    "for l in cursor.fetchall():\n",
    "    print(l)\n",
    "\n",
    "# Fecha o cursor\n",
    "cursor.close()\n",
    "# Fecha a conexÃ£o\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConclusÃ£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook apresentou como importar dados de diversos formatos para o pandas.\n",
    "\n",
    "> ðŸ”Ž **Se interessou?** DÃª uma olhada na documentaÃ§Ã£o da biblioteca *pandas* para informaÃ§Ãµes extras sobre leitura de dados:\n",
    "[IO Tools](https://pandas.pydata.org/docs/user_guide/io.html)\n",
    "\n",
    "---\n",
    "\n",
    "O prÃ³ximo notebook ([3.2.Limpeza.ipynb](3.2.Limpeza.ipynb)) apresenta como fazer a limpeza dos dados."
   ]
  }
 ],
 "metadata": {
  "julynter-results": {
   "filteredId": [],
   "filteredIndividual": [],
   "filteredRestart": [],
   "filteredType": [],
   "hash": "6b27a9fb782d43d181404925077b28607a688e69",
   "visible": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
